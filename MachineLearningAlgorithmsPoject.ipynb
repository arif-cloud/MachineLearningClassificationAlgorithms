{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Pandas library\n",
        "import pandas as pd\n",
        "# Read the preprocessed BMI dataset from a CSV file\n",
        "data = pd.read_csv(\"bmi.csv\")"
      ],
      "metadata": {
        "id": "D29e9h-ysnaL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X(Features): These are the features or attributes that a machine learning model analyzes to make predictions or learn patterns.\n",
        "X = data[['Height', 'Weight']]\n",
        "# y(Target): It is the target variable that the model aims to predict based on the input data X.\n",
        "y = data['BmiClass']\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "RMoK2XwquMDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)"
      ],
      "metadata": {
        "id": "KOxYEOQCuz9z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SVC library\n",
        "from sklearn.svm import SVC\n",
        "# Create and train Support Vector Machine (SVM) model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KSpKxf6hvN1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GaussianNB library\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Create and train Naive Bayes model\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "BN_BVNbqvjyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Neighbors library\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Create and train k-Nearest Neighbors (KNN) model\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HkuCCe5wvvOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using the trained models on the test set\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "print(svm_predictions)\n",
        "print(nb_predictions)\n",
        "print(knn_predictions)"
      ],
      "metadata": {
        "id": "PD1zoWTvv97S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Confusion Matrix library\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Calculate confusion matrices for each model\n",
        "svm_cm = confusion_matrix(y_test, svm_predictions)\n",
        "nb_cm = confusion_matrix(y_test, nb_predictions)\n",
        "knn_cm = confusion_matrix(y_test, knn_predictions)"
      ],
      "metadata": {
        "id": "WhIuL7FWwBKI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Seaborn and Matplotlib library\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot confusion matrices using Seaborn and Matplotlib\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.heatmap(svm_cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
        "plt.title('SVM Confusion Matrix')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.heatmap(nb_cm, annot=True, fmt='g', cmap='Greens', cbar=False)\n",
        "plt.title('Na√Øve Bayes Confusion Matrix')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.heatmap(knn_cm, annot=True, fmt='g', cmap='Reds', cbar=False)\n",
        "plt.title('KNN Confusion Matrix')\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ocJehjrowWJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Numpy library\n",
        "import numpy as np\n",
        "\n",
        "# Introduce missing values (NaN) in 'Height' and 'Weight' columns at random locations\n",
        "random_numbers_height = np.random.randint(0, len(data), size=40)\n",
        "data['Height'].iloc[random_numbers_height] = np.nan\n",
        "\n",
        "random_numbers_weight = np.random.randint(0, len(data), size=40)\n",
        "data['Weight'].iloc[random_numbers_weight] = np.nan\n",
        "\n",
        "# Print dataset with NaN values\n",
        "print(data)"
      ],
      "metadata": {
        "id": "ZoaBrPjeyro3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean values for 'Height' and 'Weight'\n",
        "# Replace NaN values with mean values in 'Height' and 'Weight' columns\n",
        "height_mean = data['Height'].mean()\n",
        "data['Height'].fillna(value=height_mean, inplace=True)\n",
        "\n",
        "weight_mean = data['Weight'].mean()\n",
        "data['Weight'].fillna(value=weight_mean, inplace=True)\n",
        "\n",
        "# Print dataset with Mean values\n",
        "print(data)"
      ],
      "metadata": {
        "id": "U8wYuG44zE0u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to map BMI values to BMI classes\n",
        "def bmi_class_mapping(bmi):\n",
        "    if bmi < 18.5:\n",
        "        return 0\n",
        "    elif 18.5 <= bmi < 25:\n",
        "        return 1\n",
        "    elif 25 <= bmi < 30:\n",
        "        return 2\n",
        "    elif 30 <= bmi:\n",
        "        return 3\n",
        "# Calculate BMI and BMI class for each row in the dataset\n",
        "for index, row in data.iterrows():\n",
        "    data.at[index, 'Bmi'] = row['Weight'] / (row['Height'] ** 2)\n",
        "    data.at[index, 'BmiClass'] = bmi_class_mapping(data.at[index, 'Bmi'])\n",
        "# Print dataset with Mean Values\n",
        "print(data)"
      ],
      "metadata": {
        "id": "s0bkNZua0Sa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the processed dataset to a new CSV file\n",
        "data.to_csv('processed_bmi.csv', index=False)"
      ],
      "metadata": {
        "id": "nBiptYFi0jti"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}